#%pip install -U Pyarrow


!nvcc --version


%pip install -U tensorflow[and-cuda]


import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))


from keras.callbacks import Callback
import matplotlib.pyplot as plt

class PlotLosses(Callback):
    def on_train_begin(self, logs={}):
        self.x = []
        self.losses = []
        self.val_losses = []
        self.fig = plt.figure()
        self.logs = []

    def on_epoch_end(self, epoch, logs={}):
        self.logs.append(logs)
        self.x.append(epoch)
        self.losses.append(logs.get("mean_absolute_error"))
        self.val_losses.append(logs.get("val_mean_absolute_error"))

        plt.clf()
        plt.plot(self.x, self.losses, label="mean_absolute_error")
        plt.plot(self.x, self.val_losses, label="val_mean_absolute_error")
        plt.legend()
        plt.pause(0.01)


import pandas as pd

DATAPATH = "contest/data"

d_csv = pd.read_csv(f"{DATAPATH}/fried_noodles_dataset.csv")
d_csv


from sklearn.model_selection import train_test_split

train_set, validation_set = train_test_split(d_csv, train_size=0.6)

train_set





from keras.preprocessing.image import (
    ImageDataGenerator,
    array_to_img,
    img_to_array,
    load_img,
)

train_datagen = ImageDataGenerator(
    rescale=1.0 / 255, rotation_range=180, horizontal_flip=True
)

train_generator = train_datagen.flow_from_dataframe(
    train_set,
    directory=f"{DATAPATH}/images/",
    x_col="filename",
    y_col=["meat", "veggie", "noodle"],
    class_mode="other",
    target_size=(150, 200),
)

test_dategen = ImageDataGenerator(rescale=1.0 / 255)

validation_generator = train_datagen.flow_from_dataframe(
    validation_set,
    directory=f"{DATAPATH}/images/",
    x_col="filename",
    y_col=["meat", "veggie", "noodle"],
    class_mode="other",
    target_size=(150, 200),
)


from keras.models import Model
from keras.layers import (
    Dense,
    Dropout,
    Flatten,
    Input,
    BatchNormalization,
    Conv2D,
    MaxPool2D,
)
from keras.optimizers import Adam

inputIm = Input(
    shape=(
        150,
        200,
        3,
    )
)
conv1 = Conv2D(64, 3, activation="relu")(inputIm)
conv1 = Conv2D(64, 3, activation="relu")(conv1)
conv1 = BatchNormalization()(conv1)
pool1 = MaxPool2D()(conv1)

conv2 = Conv2D(128, 3, activation="relu")(pool1)
conv2 = Conv2D(128, 3, activation="relu")(conv2)
conv2 = BatchNormalization()(conv2)
pool2 = MaxPool2D()(conv2)

conv3 = Conv2D(256, 3, activation="relu")(pool2)
conv3 = Conv2D(256, 3, activation="relu")(conv3)
conv3 = BatchNormalization()(conv3)
pool3 = MaxPool2D()(conv3)

conv4 = Conv2D(512, 3, activation="relu")(pool3)
conv4 = Conv2D(512, 3, activation="relu")(conv4)
conv4 = BatchNormalization()(conv4)
pool4 = MaxPool2D()(conv4)

"""
conv5 = Conv2D(1024,3,activation='relu')(pool4)
conv5 = Conv2D(1024,3,activation='relu')(conv5)
conv5 = BatchNormalization()(conv5)
pool5 = MaxPool2D()(conv5)
"""
flat = Flatten()(conv4)  # can be conv5

dense1 = Dense(512, activation="sigmoid")(flat)
dense1 = Dropout(0.5)(dense1)
dense1 = Dense(512, activation="sigmoid")(dense1)
dense1 = Dropout(0.5)(dense1)
dense1 = Dense(512, activation="sigmoid")(dense1)
dense1 = Dropout(0.5)(dense1)
output = Dense(3)(dense1)

model = Model(inputs=inputIm, outputs=output)

model.compile(
    optimizer=Adam(learning_rate=1e-4), loss="mse", metrics=["mean_absolute_error"]
)


from keras.callbacks import ModelCheckpoint

checkpoint = ModelCheckpoint(
    "first_food.h5",
    verbose=1,
    monitor="val_mean_absolute_error",
    save_best_only=True,
    mode="min",
)
plot_losses = PlotLosses()


# Train the Model
model.fit_generator(
    train_generator,
    steps_per_epoch=len(train_generator),
    epochs=5,
    validation_data=validation_generator,
    validation_steps=len(validation_generator),
    callbacks=[checkpoint, plot_losses],
)



